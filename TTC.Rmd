---
title: "Tanzania_Tourism_Classisfication_Challenge"
author: "Ridhiwan Mseya"
date: "6/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install packages if they dont exist

```{r, warning=FALSE}
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(readr)) install.packages("readr")
if(!require(corrplot)) install.packages("corrplot")
if(!require(caret)) install.packages("caret")
if(!require(VGAM)) install.packages("VGAM")
if(!require(RANN)) install.packages("RANN")
if(!require(RWeka)) install.packages("RWeka")
if(!require(leaps)) install.packages("leaps")
if(!require(randomForest)) install.packages("randomForest")
if(!require(ordinalForest)) install.packages("ordinalForest")
if(!require(ranger)) install.packages("ranger")
if(!require(e1071)) install.packages("e1071")
if(!require(Amelia)) install.packages("Amelia")
if(!require(xgboost)) install.packages("xgboost")
if(!require(caretEnsemble)) install.packages("caretEnsemble")
if(!require(vbmp)) install.packages("vbmp")
if(!require(moments)) install.packages("moments")


```

## load libraries and data files

  Get all the files and some of the libraries that we need to analyze data.
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)

VariableDefs <- read_csv("VariableDefinitions.csv")
test_data <- read_csv("Test.csv")
Submissionsamp <-read_csv("SampleSubmission.csv")
train_data <- read_csv("Train.csv")
```

## Check the data and remove any missing values


```{r , warning=FALSE, message=FALSE}
head(tibble(VariableDefs)) # contains definitions of each variable/column in our data
head(tibble(train_data)) # The training data for our model which will be split into test and train
head(tibble(test_data)) # The validation data for our model
head(tibble(Submissionsamp)) # The probability of each tour_id to be at a given category.

mean(is.na(train_data)) # if not zero then we have some missing values
mean(is.na(test_data)) # if not zero then we have some missing values

train_data_comp <- na.exclude(train_data) # exclude rows with any NA values
test_data_comp <- na.exclude(test_data) # exclude rows with any NA values

mean(is.na(train_data_comp)) # if not zero then we have some missing values
mean(is.na(test_data_comp)) # if not zero then we have some missing values

```
  The last datasets are complete with no missing values, we can now move on to visualizing our data.
  
```{r , message=FALSE, warning=FALSE}
#plot a graph to visualize the cost category distribution

#factor(train_data_comp$cost_category)
train_data_comp %>% summarise(cost_category) %>% ggplot(aes(cost_category)) + geom_histogram(stat = "count")

```

  If picked at random the probability of a tourist to be a in given cost category would follow this descending order:
  
  Normal Cost -> Higher Cost -> High Cost -> Low Cost -> Lower Cost -> Highest Cost
  
  To predict the cost of a single tourist correctly then we will have to investigate the variables and how they affect the cost category. Let us plot a correlation plot to get an initial picture.
  
```{r , warning=FALSE, message=FALSE}
library(corrplot)

# Make all the data numeric for correlation plots
factorized <- lapply(train_data_comp,as.factor)
corr_data <- lapply(factorized,as.numeric)
train_data_corr <- as.data.frame(corr_data)

# plot the graph
tdr <- cor(train_data_corr)
corrplot(tdr,method = "shade",order = "AOE", diag = FALSE, type = "upper", tl.srt = 90,number.font = 0.3, number.cex = 0.3 )
```

  The plot shows us that there is positive correlation between packages that tourists buy and that those packages have a negative correlation with the cost category.The higher the cost the more packages have been used. These variables will heavily affect our prediction models when tweaked.
  

## Machine Learning models

  The criteria in this project will be using the method of log loss.
  
```{r , warning=FALSE, message=FALSE}
library(caret)
library(RANN)
set.seed(28)
head(mtcars)

mtcars$vs <- as.factor(mtcars$vs)
train_ind <- createDataPartition(mtcars$vs, p = .8, 
                                  list = FALSE, times = 1)
mtcars_train <- mtcars[train_ind,]
mtcars_test <- mtcars[-train_ind,]

head(mtcars_train)
head(mtcars_test)

preProc <- preProcess(mtcars_train, method='knnImpute')
preProc

mtcars_train <- predict(preProc, newdata = mtcars_train)
anyNA(mtcars_train)

mtcars_glm_model <- train(form = vs ~ wt + disp + hp ,data = mtcars_train,
  trControl = trainControl(method = "cv", number = 5),
  method = "glm",family = "binomial"(link = "logit"))

mtcars_glm_model$results

```

  Now let us calculate the accuracy and the probabilities of the given model above.
  
```{r , message=FALSE, warning=FALSE}

calc_acc = function(actual, predicted) {
  mean(actual == predicted)
}

head(predict(mtcars_glm_model, newdata = mtcars_test))

calc_acc(actual = mtcars_test$vs,
         predicted = predict(mtcars_glm_model, newdata = mtcars_test))

head(predict(mtcars_glm_model, newdata=mtcars_test, type = "prob"))


```

```{r}
str(train_data)
```

  Now we will  test the model using our actual data for this project
  


By examining the table of best models printed above we will go through the best model which is the last one and eliminate all variables that have only FALSE values and leave those with even one TRUE value.

```{r}
t <- as.tibble(b.summary$which)
t[16,]
str(train_set)
str(test_set)
```



  
### Imputation of missing data
  
```{r , warning=FALSE, message=FALSE}
library(Amelia)
set.seed(26 )

train_data_f <- data.frame(lapply(train_data[,c(2,3,4,7,8,9,10,11,12,13,14,15,16,17,20,21)],factor))

train_data_f <- train_data_f %>%
  add_column(Tour_ID = train_data$Tour_ID,
             .before = "country") %>% add_column(total_male=train_data$total_male, .before = "purpose") %>% add_column(total_female=train_data$total_female, .before = "total_male") %>% add_column(night_zanzibar=train_data$night_zanzibar, .before = "first_trip_tz")  %>% add_column(night_mainland=train_data$night_mainland, .before = "night_zanzibar")  

missmap(train_data_f)


impute_train_data <- amelia(train_data_f, m=5, idvars = c("Tour_ID","package_accomodation","tour_arrangement","package_sightseeing","package_guided_tour","package_transport_tz","package_transport_int","package_food","age_group","country","night_mainland","night_zanzibar","info_source","package_insurance"), noms = c(4,7,8,20), ords = "cost_category")

#head(impute_train_data)
summary(impute_train_data)

write.amelia(impute_train_data,file.stem = "imputed_train_data")

train_data1 <- read_csv("imputed_train_data1.csv")

train_data1 <- train_data1[,2:22]

head(as.tibble(train_data1))

missmap(train_data1)
```



```{r , warning=FALSE, message=FALSE}
library(Amelia)
set.seed(26 )

test_data_f <- data.frame(lapply(test_data[,c(2,3,4,7,8,9,10,11,12,13,14,15,16,17,20)],factor))

test_data_f <- test_data_f %>%
  add_column(Tour_ID = test_data$Tour_ID,
             .before = "country") %>% add_column(total_male=test_data$total_male, .before = "purpose") %>% add_column(total_female=test_data$total_female, .before = "total_male") %>% add_column(night_zanzibar=test_data$night_zanzibar, .before = "first_trip_tz")  %>% add_column(night_mainland=test_data$night_mainland, .before = "night_zanzibar")  

missmap(test_data_f)


impute_test_data <- amelia(test_data_f, m=5, idvars = c("Tour_ID","package_accomodation","tour_arrangement","package_sightseeing","package_guided_tour","package_transport_tz","package_transport_int","package_food","age_group","country","night_mainland","night_zanzibar","info_source","package_insurance"), noms = c(4,7,8,20))

#head(impute_train_data)
summary(impute_test_data)

write.amelia(impute_test_data,file.stem = "imputed_test_data")

test_data1 <- read_csv("imputed_test_data2.csv")

test_data1 <- test_data1[,2:21]

head(as.tibble(test_data1))

missmap(test_data1)
```

  We will now create hot encoding of our data using the caret package and observe if that will improve the results of our models.


```{r}
# If traindata1 is ever to change then we have traindata11 as a backup which doesnt need any changing
set.seed(23)
anyNA(train_data1)
head(train_data1)
#train_data11 <- train_data1

library(caret)
dummy <- dummyVars("cost_category ~  info_source + package_transport_tz + package_food + main_activity + package_transport_int + package_accomodation + tour_arrangement + age_group + purpose + night_mainland + night_zanzibar + first_trip_tz + travel_with + package_guided_tour + package_insurance + package_sightseeing", data = train_data1, fullRank = TRUE)
train_data2 <- data.frame(predict(dummy, newdata=train_data1))

train_data2 <- train_data2 %>% add_column(cost_category = train_data1$cost_category) %>% add_column(total_female = train_data1$total_female) %>% add_column(total_male = train_data1$total_male) %>% add_column(country = train_data1$country)

train_data2$cost_category <- as.factor(train_data2$cost_category)
levels(train_data2$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

anyNA(train_data2)
```

  Hot encoding for our validation data.

```{r}
set.seed(23)
anyNA(test_data1)
head(test_data1)
dummy <- dummyVars(" ~  info_source + package_transport_tz + package_food + main_activity + package_transport_int + package_accomodation + tour_arrangement + age_group + purpose + night_mainland + night_zanzibar + first_trip_tz + travel_with + package_guided_tour + package_insurance + package_sightseeing", data = train_data1, fullRank = TRUE)
test_data2 <- data.frame(predict(dummy, newdata=test_data1))

test_data2 <- test_data2 %>% add_column(total_female = test_data1$total_female) %>% add_column(total_male = test_data1$total_male) %>% add_column(country = test_data1$country)

anyNA(test_data2)

```






  Check high skewness and correlation of the data the preprocess it for better accuracy of our models. This is crazy actually, we can only preprocess continuos data and that is what I should do with the total female, total male and night_mainland and night_zanzibar.
```{r , message=FALSE, warning=FALSE}
set.seed(20)
library(moments)
skewness(train_data2[c(33,34,44,45)])
skewness(test_data2[c(33,34,43,44)])

c4 <- preProcess(train_data2[c(33,34,44,45)], method = c("center","scale","BoxCox","YeoJohnson","zv","nzv"))
c4_df <- predict(c4,train_data2[c(33,34,44,45)])
#head(c4_df)
#skewness(c4_df)

d4 <- preProcess(test_data2[c(33,34,43,44)], method = c("center","scale","BoxCox","YeoJohnson","zv","nzv"))
d4_df <- predict(d4,test_data2[c(33,34,43,44)])
#head(d4_df)
#skewness(d4_df)

train_int <- cbind(train_data2[-c(33,34,44,45)],c4_df)
#head(train_int)

test_int <- cbind(test_data2[-c(33,34,43,44)],d4_df)
#head(test_int)

pp_train <- preProcess(train_int[-c(41,42)], method = "corr")
train_data5 <- predict(pp_train,train_int[-c(41,42)])

pp_test <- preProcess(test_data2[-45], method = "corr")
test_data5 <- predict(pp_test,test_data2[-45])


```

Adding back the tour_ID to both test and train data.

```{r}
train_data5 <- train_data5 %>% add_column(Tour_ID = train_data1$Tour_ID) %>% add_column(cost_category = train_data1$cost_category) %>% add_column(country=train_data1$country)
test_data5 <- test_data5 %>% add_column(Tour_ID = test_data1$Tour_ID) %>% add_column(country=test_data1$country)

```


  We need to add the country column to our data but it has too many levels if factorized. We will device a way to factorize it with a few levels before checking its importance as a variable in the following steps.
```{r}
#country_df <- as.data.frame(table(train_data5$country))
#country_df <- country_df[order(country_df$Freq,decreasing=TRUE),]
#country_df
#country_df[country_df$Freq > 180,]

#country_df$Var1 <- factor(country_df$Var1,levels = c("ITALY","FRANCE","GERMANY","UNITED STATES OF AMERICA","SOUTH AFRICA", "UNITED KINGDOM", "KENYA", "ZAMBIA", "AUSTRALIA","CANADA","ZIMBABWE","UGANDA","SPAIN","INDIA","NETHERLANDS","SWIZERLAND","BELGIUM","SWEDEN","BURUNDI","CHINA", "UAE"))
#country_df$Var1 <-`levels<-`(addNA(country_df$Var1), c(levels(country_df$Var1),"OTHERS"))
#str(country_df)

train_data5$country <- factor(train_data5$country,levels = c("ITALY","FRANCE","GERMANY","UNITED STATES OF AMERICA","SOUTH AFRICA", "UNITED KINGDOM", "KENYA", "ZAMBIA", "AUSTRALIA","CANADA","ZIMBABWE","UGANDA","SPAIN","INDIA","NETHERLANDS","SWIZERLAND","BELGIUM","SWEDEN","BURUNDI","CHINA", "UAE"))
train_data5$country <- `levels<-`(addNA(train_data5$country), c(levels(train_data5$country),"OTHERS"))
str(train_data5)

test_data5$country <- factor(test_data5$country,levels = c("ITALY","FRANCE","GERMANY","UNITED STATES OF AMERICA","SOUTH AFRICA", "UNITED KINGDOM", "KENYA", "ZAMBIA", "AUSTRALIA","CANADA","ZIMBABWE","UGANDA","SPAIN","INDIA","NETHERLANDS","SWIZERLAND","BELGIUM","SWEDEN","BURUNDI","CHINA", "UAE"))
test_data5$country <- `levels<-`(addNA(test_data5$country), c(levels(test_data5$country),"OTHERS"))
str(test_data5)

```


  Now its is time for selecting features to include in our model

```{r}
# Feature selection
corr <- lapply(train_data5,as.numeric)
corMat <- as.data.frame(corr)
highcor <- findCorrelation(corMat,cutoff = 0.9 , exact = FALSE, names = TRUE)
highcor
#train_data3 <- train_data2[,-c(33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 12, 13)]

#ctrl <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 2)
#outcome <- "cost_category"
#predictors <- names(train_data3)[!names(train_data3) %in% outcome]
#pred_prof <- rfe(train_data3[,predictors], train_data3[,outcome], rfeControl = ctrl)
#pred_prof

```

  By accuracy measures it shows that addition features only improves models and we should not exclude them early on.


```{r}
#memory.size(max = TRUE)
#memory.limit(size = 9000)
```

### The most important variables

```{r , warning=FALSE, message=FALSE}
train_data4 <- train_data5
names(train_data4)[1:45] <- paste("var",1:45,sep="")
names(train_data4)[44] <- "cost_category"
names(train_data4)[43] <- "Tour_ID"
names(train_data4)

train_data4$cost_category <- as.factor(train_data4$cost_category)
levels(train_data4$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")


test_data4 <- test_data5
names(test_data4)[1:45] <- paste("var",1:45,sep="")
names(test_data4)[44] <- "Tour_ID"
names(test_data4)
```

```{r , warning=FALSE, message=FALSE}
set.seed(23)
library(leaps)
#train_data$cost_category <- as.factor(train_data$cost_category)
#levels(train_data$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

#train_data_f <- data.frame(lapply(train_data1[,c(2,3,4,7,8,9,10,11,12,13,14,15,16,17,20,21)],factor))

#train_data_sub <- train_data[sample(nrow(train_data),2000),]

x <- model.matrix(cost_category ~ . , data = train_data4)

y <- train_data4$cost_category

#length(y)
 
bestmods <- regsubsets(x, y, nbest=1,  method=c("exhaustive","forward", "backward", "seqreq"), nvmax = 45) 

b.summary <- summary(bestmods)

names(b.summary)

plot(b.summary$rsq, xlab="#num", ylab="rsq", type = "l") #8
plot(b.summary$rss, xlab="#num", ylab="rss", type = "l") #8
plot(b.summary$adjr2, xlab="#num", ylab="adjr2", type = "l") #8
plot(b.summary$cp, xlab="#num", ylab="cp", type = "l") #8
plot(b.summary$bic, xlab="#num", ylab="bic", type = "l") #8

df <- as.tibble(b.summary$which)
df
as.data.frame(colMeans(df))
```

```{r}
df_sort <- as.data.frame(colMeans(df))
df_sort <- df_sort %>% add_column(var = 1:42)
names(df_sort)[1] <- "mean"
df_sort
df_sort[order(-df_sort$mean),]
```


```{r}
set.seed(22)
mod  <- train(cost_category ~ ., data = train_data4[c(40:45)], method = "RRF")
varImp(mod)

```

 A list of 26 variables in train_data4 with the most contribution to prediction are:
 var(8,9,19,24,7,29,15,17,22,27,31,36,37,38,39,40,41,42.45)


By examining the table of best models printed above we will go through the best model which is the last one and eliminate all variables that have only FALSE values and leave those with even one TRUE value

```{r}
t <- as.tibble(b.summary$which)
t[16,]
#str(train_set)
#str(test_set)

my_form <- as.formula(paste("cost_category ~ ", paste(paste0("var",c(8,9,19,24,7,29,15,17,22,27,31,36,37,38,39,40,41,42,45)), collapse = "+")))
```

We should consider excluding the following variables:

  1. info_source
  2. package_transport_tz
  3. package_food
  4. package_insurance
  5. package_sightseeing
  6. package_guided_tour
  
We should consider using the following variables in our models:
  1. main_activity
  2. package_transport_int
  3. package_accommodation
  4. tour_arrangement
  5. country
  6. age_group
  7. purpose
  8. night_mainland
  9. night_zanzibar
  10. first_trip_tz



### First Model

```{r ,warning=FALSE, message=FALSE}
set.seed(29)

train_ind <- createDataPartition(train_data4$cost_category, p = .8, 
                                  list = FALSE, times = 1)

#train_set <- train_data4[train_ind,]
#test_set <- train_data4[-train_ind,]
train_set <- train_data4

#preProc <- preProcess(as.data.frame(train_set), method = ("knnImpute"))
#preProc

#train_set <- predict(preProc, newdata = train_set)

#dummyModel <- dummyVars(cost_category ~ main_activity + package_transport_int + package_accomodation + tour_arrangement + age_group + purpose + night_mainland + first_trip_tz, data = train_set)
#train_setX <- as.data.frame(predict(dummyModel, newdata = train_set))

#rangeModel <- preProcess(train_setX, method = "range")
#train_setX <- predict(rangeModel, newdata = train_setX)

#train_set <- cbind(train_set$cost_category, train_setX)
#names(train_set)[1] <- "cost_category"

#test_set_imputed <- predict(preProc, test_set)
#test_set_dummy <- predict(dummyModel, test_set_imputed)
#test_set_range <- predict(rangeModel, test_set_dummy)
#test_set_range <- data.frame(test_set_range)
#test_set <- cbind(test_set$cost_category, test_set_range)
#names(test_set) <- names(train_set)

anyNA(train_set)
anyNA(test_set)

#ctrl<-trainControl(method = "repeatedcv", number=10 , repeats = 5, classProbs = TRUE)
ctrl<-trainControl(method = "repeatedcv", number=4 , repeats = 4, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss, savePredictions = "final")
grid<-expand.grid(decay=seq(0,1,by=0.1)) 


#nn_model <- nnet::multinom(cost_category ~ ., data= train_set)
mltn_model <- train(form = my_form ,data = train_set, trControl = ctrl,
  method = "multinom", metric="Logloss", maxit=1000, tuneGrid=grid)

mltn_model$results

```  

```{r}
min(mda_model$results$logLoss)
```



### First Model two

```{r ,warning=FALSE, message=FALSE}
set.seed(29)
library(VGAM) # method 'vglmAdjCat' is the one that worked



train_ind <- createDataPartition(train_data4$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data4[train_ind,]
test_set <- train_data4[-train_ind,]

#preProc <- preProcess(as.data.frame(train_set), method = ("knnImpute"))
#preProc

#train_set <- predict(preProc, newdata = train_set)

#dummyModel <- dummyVars(cost_category ~ main_activity + package_transport_int + package_accomodation + tour_arrangement + age_group + purpose + night_mainland + first_trip_tz, data = train_set)
#train_setX <- as.data.frame(predict(dummyModel, newdata = train_set))

#rangeModel <- preProcess(train_setX, method = "range")
#train_setX <- predict(rangeModel, newdata = train_setX)

#train_set <- cbind(train_set$cost_category, train_setX)
#names(train_set)[1] <- "cost_category"

#test_set_imputed <- predict(preProc, test_set)
#test_set_dummy <- predict(dummyModel, test_set_imputed)
#test_set_range <- predict(rangeModel, test_set_dummy)
#test_set_range <- data.frame(test_set_range)
#test_set <- cbind(test_set$cost_category, test_set_range)
#names(test_set) <- names(train_set)

anyNA(train_set)
anyNA(test_set)

#ctrl<-trainControl(method = "repeatedcv", number=10 , repeats = 5, classProbs = TRUE)
ctrl<-trainControl(method = "repeatedcv", number=1 , repeats = 2, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss, savePredictions = "final")
#grid<-expand.grid(parallel=FALSE, link= "loge") 


mda_model <- train(form= cost_category ~ .,data = train_set, trControl = ctrl,
  method = "manb", metric="logLoss")

mda_model$results

```



### Second Model

```{r , warning=FALSE, message=FALSE}
set.seed(26 )
library(randomForest)
library(e1071)
library(ranger)
library(ordinalForest)
library(xgboost)
library(maboost)


#train_data1$cost_category <- as.factor(train_data$cost_category)
#levels(train_data1$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

train_ind <- createDataPartition(train_data4$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data4[train_ind,]
test_set <- train_data4[-train_ind,]

#preProc <- preProcess(as.data.frame(train_set), method = c("center", "scale", "YeoJohnson"))
#preProc

#train_set1 <- predict(preProc, newdata = train_set)

anyNA(train_set)
anyNA(test_set)

ctrl<-trainControl(method = "repeatedcv", number=3  , repeats = 2, classProbs = TRUE, search = "grid", selectionFunction = "oneSE",  summaryFunction=mnLogLoss, savePredictions = "final")
#mtry <- sqrt(ncol(x))
#ctrl<-trainControl(method = "repeatedcv", number=5, repeats = 2, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
#grid<-expand.grid(C50tree=TRUE) 


#nn_model <- nnet::multinom(cost_category ~ ., data= train_set)
xg_model <- train(form = my_form ,data = train_set, trControl = ctrl,
  method = "xgbTree", metric="Logloss", tuneLength=10)

xg_model$results
```

### Second Model two

```{r , warning=FALSE, message=FALSE}
library(caTools) 
set.seed(26 )


#train_data1$cost_category <- as.factor(train_data1$cost_category)
#levels(train_data1$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

#train_data1$cost_category <- factor(train_data1$cost_category, ordered = TRUE ,levels = c("Lower_Cost","Low_Cost",  "Normal_Cost","High_Cost","Higher_Cost", "Highest_Cost"))

train_ind <- createDataPartition(train_data4$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data4[train_ind,]
test_set <- train_data4[-train_ind,]

#train_set <- train_data4

anyNA(train_set)
anyNA(test_set)

#ctrl<-trainControl(method = "repeatedcv", number=5 , repeats = 2, classProbs = TRUE)
ctrl<-trainControl(method = "repeatedcv", number=3 , repeats = 2,summaryFunction=mnLogLoss, selectionFunction = "oneSE",classProbs = TRUE, savePredictions = "final")
#ctrl<-trainControl(method = "boot632", number=10 , selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
#grid<-expand.grid(nIter =31)

lgt_model <- train(form = my_form  ,data = train_set, trControl = ctrl,
  method = "LogitBoost", metric = "Logloss")

lgt_model$results

```

```{r}
mda_model$bestTune
```
The above model has not performed well compared to the first model.

### Third Model

```{r , warning=FALSE, message=FALSE}
library(RWeka) 
set.seed(26 )

#train_data1$cost_category <- factor(train_data2$cost_category, ordered = TRUE ,levels = c("Lower_Cost","Low_Cost","Normal_Cost","High_Cost","Higher_Cost","Highest_Cost"))

train_ind <- createDataPartition(train_data4$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data4[train_ind,]
test_set <- train_data4[-train_ind,]


#anyNA(train_set1)

ctrl<-trainControl(method = "repeatedcv", number=3  , repeats = 2, classProbs = TRUE, selectionFunction = "oneSE",  summaryFunction=mnLogLoss, savePredictions = "final")
#ctrl<-trainControl(method = "boot632", number=10, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
#grid<-expand.grid(data.frame(.iter = 4))


lmt_model <- train(form =  my_form,data = train_set, trControl = ctrl,
  method = "LMT", metric = "logLoss", tuneLength = 3)

lmt_model$results

```
Worked better than the second model but not like the first model.


### Fourth Model

```{r , warning=FALSE, message=FALSE}
library(MASS)
library(e1071)
set.seed(26 )

#train_data1$cost_category <- as.factor(train_data1$cost_category)
#levels(train_data1$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

train_ind <- createDataPartition(train_data4$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data4[train_ind,]
test_set <- train_data4[-train_ind,]



anyNA(train_set)

ctrl<-trainControl(method = "repeatedcv", number=3,repeats = 2, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss, savePredictions = "final")
#grid<-expand.grid(maxiter = 20) 


nnet_model <- train(form = my_form, trControl = ctrl,
  method = "nnet", metric = "logLoss", tuneLength=2,data=train_set, maxit=1000)

nnet_model$results

```
This model computes quickly but its results are the worst compared to all previous models.

```{r , message=FALSE, warning=FALSE}
mdls_compare <- resamples(list(MLT=mltn_model,LGB=lgt_model,XGB=xg_model,NET=nnet_model,LMT=lmt_model))
summary(mdls_compare)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(mdls_compare,scales=scales )
```
  create an ensembled model
  
```{r ,warning=FALSE, message=FALSE}
library(caretEnsemble)
ctrl1 <- trainControl(method = "repeatedcv",number = 3, repeats = 2, savePredictions = TRUE)
algolst  <- c("multinom","LogitBoost","xgbTree","nnet","LMT")

set.seed(25)

mdls <- caretList(my_form,trControl=ctrl1,methodList=algolst,data=train_data4)
rslts <- resamples(mdls)
summary(rslts)
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(rslts,scales=scales)
```
  Ensemble prediction
```{r}
#check for models with very high correlations
modelCor(rslts)
#Combinations to consider: 1. (nnet,multinom) 2. (LMT,xgbTree) 3.(LMT,nnet)

#ctrl2 <- trainControl(method = "boot632", number=10, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss, )
#glm_ens <- caretStack(mdls,method="glm",metric="Logloss")
#glm_ens$results

trainSet <- train_set
testSet <- test_set

mltn_pred <- mltn_model$pred
nnet_pred <- nnet_model$pred
lmt_pred <- lmt_model$pred

mltn_pred2 <- mltn_pred[mltn_pred$Resample %in% c("Fold1.Rep2","Fold2.Rep2","Fold3.Rep2"),  ]
nnet_pred2 <- nnet_pred[nnet_pred$Resample %in% c("Fold1.Rep2","Fold2.Rep2","Fold3.Rep2"),  ]
lmt_pred2 <- lmt_pred[lmt_pred$Resample %in% c("Fold1.Rep2","Fold2.Rep2","Fold3.Rep2"),  ]

trainSet$OOF_pred_mltn <- mltn_pred2$pred[order(mltn_pred2$rowIndex)]
trainSet$OOF_pred_nnet <- nnet_pred2$pred[order(nnet_pred2$rowIndex)]
trainSet$OOF_pred_lmt <- lmt_pred2$pred[order(lmt_pred2$rowIndex)]

# predictors for the top layer model
predictors_top <- c("OOF_pred_mltn","OOF_pred_nnet","OOF_pred_lmt")

# Logitboost as top layer
head(trainSet[,predictors_top])
head(trainSet[,"cost_category"])

ctrl<-trainControl(method = "repeatedcv", number=3 , repeats = 2,summaryFunction=mnLogLoss, selectionFunction = "oneSE",classProbs = TRUE, savePredictions = "final")

lgt_ens <- train(trainSet[,predictors_top],trainSet[,"cost_category"],  trControl = ctrl,method = "nnet", metric = "Logloss", tuneLength=3, maxit = 1000)

lgt_ens$results

```




  Now let us calculate the accuracy and the probabilities of the given model above.
  
```{r , message=FALSE, warning=FALSE}

#head(predict(nn_model, newdata = test_set))

head(predict(mltn_model, newdata=test_set, type = "prob"))


results_table <- predict(mltn_model, newdata=test_set, type = "prob")

results_table <- results_table %>% rename(c("High Cost"=High_Cost,"Higher Cost"=Higher_Cost, "Highest Cost"=Highest_Cost, "Low Cost"=Low_Cost, "Lower Cost"=Lower_Cost, "Normal Cost"=Normal_Cost))

results_table <- results_table %>%
  add_column(Tour_ID = test_set$Tour_ID,
             .before = "High Cost") 

results_table

```
  We then create our submission file for the competition by getting results from our validation set.
  
```{r , message=FALSE, warning=FALSE}

head(predict(lgt_model, newdata=test_data4, type = "prob"))

final_table <- predict(lgt_model, newdata=test_data4, type = "prob")

final_table <- final_table %>% rename(c("High Cost"=High_Cost,"Higher Cost"=Higher_Cost, "Highest Cost"=Highest_Cost, "Low Cost"=Low_Cost, "Lower Cost"=Lower_Cost, "Normal Cost"=Normal_Cost))

final_table <- final_table %>%
  add_column(Tour_ID = test_data4$Tour_ID,
             .before = "High Cost") 

final_table

write.csv(final_table,file = "final_table.csv", row.names = FALSE)


```
  Investigate the final file for missing values
  
```{r , warning=FALSE, message=FALSE}
final_table[final_table$Tour_ID=="tour_idnup62oa8",]

```

