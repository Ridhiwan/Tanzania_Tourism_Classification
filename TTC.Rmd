---
title: "Tanzania_Tourism_Classisfication_Challenge"
author: "Ridhiwan Mseya"
date: "6/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install packages if they dont exist

```{r, warning=FALSE}
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(readr)) install.packages("readr")
if(!require(corrplot)) install.packages("corrplot")
if(!require(caret)) install.packages("caret")
if(!require(VGAM)) install.packages("VGAM")
if(!require(RANN)) install.packages("RANN")
if(!require(RWeka)) install.packages("RWeka")
if(!require(leaps)) install.packages("leaps")

```

## load libraries and data files

  Get all the files and some of the libraries that we need to analyze data.
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)

VariableDefs <- read_csv("VariableDefinitions.csv")
test_data <- read_csv("Test.csv")
Submissionsamp <-read_csv("SampleSubmission.csv")
train_data <- read_csv("Train.csv")
```

## Check the data and remove any missing values


```{r , warning=FALSE, message=FALSE}
head(tibble(VariableDefs)) # contains definitions of each variable/column in our data
head(tibble(train_data)) # The training data for our model which will be split into test and train
head(tibble(test_data)) # The validation data for our model
head(tibble(Submissionsamp)) # The probability of each tour_id to be at a given category.

mean(is.na(train_data)) # if not zero then we have some missing values
mean(is.na(test_data)) # if not zero then we have some missing values

train_data_comp <- na.exclude(train_data) # exclude rows with any NA values
test_data_comp <- na.exclude(test_data) # exclude rows with any NA values

mean(is.na(train_data_comp)) # if not zero then we have some missing values
mean(is.na(test_data_comp)) # if not zero then we have some missing values

```
  The last datasets are complete with no missing values, we can now move on to visualizing our data.
  
```{r , message=FALSE, warning=FALSE}
#plot a graph to visualize the cost category distribution

#factor(train_data_comp$cost_category)
train_data_comp %>% summarise(cost_category) %>% ggplot(aes(cost_category)) + geom_histogram(stat = "count")

```

  If picked at random the probability of a tourist to be a in given cost category would follow this descending order:
  
  Normal Cost -> Higher Cost -> High Cost -> Low Cost -> Lower Cost -> Highest Cost
  
  To predict the cost of a single tourist correctly then we will have to investigate the variables and how they affect the cost category. Let us plot a correlation plot to get an initial picture.
  
```{r , warning=FALSE, message=FALSE}
library(corrplot)

# Make all the data numeric for correlation plots
factorized <- lapply(train_data_comp,as.factor)
corr_data <- lapply(factorized,as.numeric)
train_data_corr <- as.data.frame(corr_data)

# plot the graph
tdr <- cor(train_data_corr)
corrplot(tdr)
```

  The plot shows us that there is positive correlation between packages that tourists buy and that those packages have a negative correlation with the cost category.The higher the cost the more packages have been used. These variables will heavily affect our prediction models when tweaked.
  

## Machine Learning models

  The criteria in this project will be using the method of log loss.
  
```{r , warning=FALSE, message=FALSE}
library(caret)
library(RANN)
set.seed(28)
head(mtcars)

mtcars$vs <- as.factor(mtcars$vs)
train_ind <- createDataPartition(mtcars$vs, p = .8, 
                                  list = FALSE, times = 1)
mtcars_train <- mtcars[train_ind,]
mtcars_test <- mtcars[-train_ind,]

head(mtcars_train)
head(mtcars_test)

preProc <- preProcess(mtcars_train, method='knnImpute')
preProc

mtcars_train <- predict(preProc, newdata = mtcars_train)
anyNA(mtcars_train)

mtcars_glm_model <- train(form = vs ~ wt + disp + hp ,data = mtcars_train,
  trControl = trainControl(method = "cv", number = 5),
  method = "glm",family = "binomial"(link = "logit"))

mtcars_glm_model$results

```

  Now let us calculate the accuracy and the probabilities of the given model above.
  
```{r , message=FALSE, warning=FALSE}

calc_acc = function(actual, predicted) {
  mean(actual == predicted)
}

head(predict(mtcars_glm_model, newdata = mtcars_test))

calc_acc(actual = mtcars_test$vs,
         predicted = predict(mtcars_glm_model, newdata = mtcars_test))

head(predict(mtcars_glm_model, newdata=mtcars_test, type = "prob"))


```

```{r}
str(train_data)
```

  Now we will  test the model using our actual data for this project
  
### The most important variables

```{r , warning=FALSE, message=FALSE}
set.seed(23)
library(leaps)

train_data$cost_category <- as.factor(train_data$cost_category)
levels(train_data$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

#train_data_f <- data.frame(lapply(train_data[,2:21],factor))

#train_data_sub <- train_data[sample(nrow(train_data),2000),]

x <- model.matrix(cost_category ~ info_source + main_activity + package_transport_tz + package_transport_int + package_accomodation + package_food + package_insurance + tour_arrangement + package_sightseeing + package_guided_tour + country + age_group + purpose + night_mainland + night_zanzibar + first_trip_tz , data = train_data)

y <- train_data$cost_category

length(y)
 
bestmods <- regsubsets(x, y, nbest=1,  method=c("forward", "backward", "seqreq"), nvmax = 15) 

b.summary <- summary(bestmods)

names(b.summary)

plot(b.summary$rsq, xlab="#num", ylab="rsq", type = "l") #8
plot(b.summary$rss, xlab="#num", ylab="rss", type = "l") #8
plot(b.summary$adjr2, xlab="#num", ylab="adjr2", type = "l") #8
plot(b.summary$cp, xlab="#num", ylab="cp", type = "l") #8
plot(b.summary$bic, xlab="#num", ylab="bic", type = "l") #8

as.tibble(b.summary$which)
```

By examining the table of best models printed above we will go through the best model which is the last one and eliminate all variables that have only FALSE values and leave those with even one TRUE value.

```{r}
t <- as.tibble(b.summary$which)
t[16,]
```

We should consider excluding the following variables:
  1. info_source
  2. package_transport_tz
  3. package_food
  4. package_insurance
  5. package_sightseeing
  6. package_guided_tour
  
We should consider using the following variables in our models:
  1. main_activity
  2. package_transport_int
  3. package_accommodation
  4. tour_arrangement
  5. country
  6. age_group
  7. purpose
  8. night_mainland
  9. night_zanzibar
  10. first_trip_tz
  
### First Model   
  
```{r , warning=FALSE, message=FALSE}
library(VGAM) # method 'vglmAdjCat' is the one that worked
set.seed(26 )

train_ind <- createDataPartition(train_data$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data[train_ind,]
test_set <- train_data[-train_ind,]

#preProc <- preProcess(as.data.frame(train_set), method = c("center", "scale", "YeoJohnson"))
#preProc

#train_set1 <- predict(preProc, newdata = train_set)

#anyNA(train_set1)

ctrl<-trainControl(method = "boot632", number=10, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
#grid<-expand.grid(parallel=FALSE, link= "loge") 


#nn_model <- nnet::multinom(cost_category ~ ., data= train_set)
mda_model <- train(form = cost_category ~ info_source + main_activity + package_transport_tz + package_transport_int + package_accomodation + package_food    + package_insurance + tour_arrangement ,data = train_set, trControl = ctrl,
  method = "vglmAdjCat", metric = "logLoss")

mda_model$results

```

### Second Model

```{r , warning=FALSE, message=FALSE}
library(caTools) 
set.seed(26 )

train_data$cost_category <- as.factor(train_data$cost_category)
levels(train_data$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

train_ind <- createDataPartition(train_data$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data[train_ind,]
test_set <- train_data[-train_ind,]

preProc <- preProcess(as.data.frame(train_set), method = c("center", "scale", "YeoJohnson", "BoxCox"))
preProc

train_set1 <- predict(preProc, newdata = train_set)

#anyNA(train_set1)

ctrl<-trainControl(method = "boot632", number=2 , selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
grid<-expand.grid(nIter = 2) 


#nn_model <- nnet::multinom(cost_category ~ ., data= train_set)
mda_model <- train(form = cost_category ~ . ,data = train_set, trControl = ctrl,
  method = "LogitBoost", metric = "logLoss", na.action = na.exclude)

mda_model$results

```
The above model has not performed well compared to the first model.

### Third Model

```{r , warning=FALSE, message=FALSE}
library(RWeka) 
set.seed(26 )

train_data$cost_category <- as.factor(train_data$cost_category)
levels(train_data$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

train_ind <- createDataPartition(train_data$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data[train_ind,]
test_set <- train_data[-train_ind,]

preProc <- preProcess(as.data.frame(train_set), method = c("center", "scale", "YeoJohnson"))
#preProc

train_set1 <- predict(preProc, newdata = train_set)

#anyNA(train_set1)

ctrl<-trainControl(method = "boot632", number=10, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
grid<-expand.grid(iter = 20) 


#nn_model <- nnet::multinom(cost_category ~ ., data= train_set)
mda_model <- train(form =  cost_category ~ info_source + main_activity + package_transport_tz + package_transport_int + package_accomodation + package_food    + package_insurance + tour_arrangement,data = train_set1, trControl = ctrl,
  method = "LMT", metric = "logLoss", na.action = na.exclude, tuneGrid=grid)

mda_model$results

```
Worked better than the second model but not like the first model.


### Fourth Model

```{r , warning=FALSE, message=FALSE}
library(MASS) 
set.seed(26 )

train_data$cost_category <- as.factor(train_data$cost_category)
levels(train_data$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

train_ind <- createDataPartition(train_data$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data[train_ind,]
test_set <- train_data[-train_ind,]

preProc <- preProcess(as.data.frame(train_set), method = c("center", "scale", "YeoJohnson"))
#preProc

train_set1 <- predict(preProc, newdata = train_set)

#anyNA(train_set1)

ctrl<-trainControl(method = "repeatedcv", number=10, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
#grid<-expand.grid(iter = 20) 


#nn_model <- nnet::multinom(cost_category ~ ., data= train_set)
mda_model <- train(form = cost_category ~ main_activity  + package_transport_int + package_accomodation + tour_arrangement + age_group + purpose + night_mainland + night_zanzibar + first_trip_tz ,data = train_set1, trControl = ctrl,
  method = "polr", metric = "logLoss", na.action = na.exclude)

mda_model$results

```
This model computes quickly but its results are the worst compared to all previous models.

### Fourth Model

```{r , warning=FALSE, message=FALSE}
library(ObliqueRF) 
set.seed(26 )

train_data$cost_category <- as.factor(train_data$cost_category)
levels(train_data$cost_category) <- c("High_Cost","Higher_Cost", "Highest_Cost", "Low_Cost", "Lower_Cost", "Normal_Cost")

train_ind <- createDataPartition(train_data$cost_category, p = .8, 
                                  list = FALSE, times = 1)


train_set <- train_data[train_ind,]
test_set <- train_data[-train_ind,]

preProc <- preProcess(as.data.frame(train_set), method = c("center", "scale", "YeoJohnson"))
#preProc

train_set1 <- predict(preProc, newdata = train_set)

#anyNA(train_set1)

ctrl<-trainControl(method = "cv", number=10, selectionFunction = "oneSE", classProbs = TRUE,  summaryFunction=mnLogLoss)
#grid<-expand.grid(iter = 20) 


#nn_model <- nnet::multinom(cost_category ~ ., data= train_set)
mda_model <- train(form = cost_category ~ info_source + main_activity + package_transport_tz + package_transport_int + package_accomodation + package_food    + package_insurance + tour_arrangement ,data = train_set1, trControl = ctrl,
  method = "ORFlog", metric = "logLoss", na.action = na.exclude)

mda_model$results

```



  Now let us calculate the accuracy and the probabilities of the given model above.
  
```{r , message=FALSE, warning=FALSE}

#head(predict(nn_model, newdata = test_set))

head(predict(mda_model, newdata=test_set, type = "prob"))


results_table <- predict(mda_model, newdata=test_set, type = "prob")

results_table <- results_table %>% rename(c("High Cost"=High_Cost,"Higher Cost"=Higher_Cost, "Highest Cost"=Highest_Cost, "Low Cost"=Low_Cost, "Lower Cost"=Lower_Cost, "Normal Cost"=Normal_Cost))

results_table <- results_table %>%
  add_column(Tour_ID = test_set$Tour_ID,
             .before = "High Cost") 

results_table

```
  We then create our submission file for the competition by getting results from our validation set.
  
```{r , message=FALSE, warning=FALSE}

head(predict(mda_model, newdata=test_data, type = "prob"))

final_table <- predict(mda_model, newdata=test_data, type = "prob")

final_table <- final_table %>% rename(c("High Cost"=High_Cost,"Higher Cost"=Higher_Cost, "Highest Cost"=Highest_Cost, "Low Cost"=Low_Cost, "Lower Cost"=Lower_Cost, "Normal Cost"=Normal_Cost))

final_table <- final_table %>%
  add_column(Tour_ID = test_data$Tour_ID,
             .before = "High Cost") 

final_table

write.csv(final_table,file = "final_table.csv", row.names = FALSE)


```
  Investigate the final file for missing values
  
```{r , warning=FALSE, message=FALSE}
final_table[final_table$Tour_ID=="tour_idnup62oa8",]

```

